{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfSusZviFVHUz3RPgLrYfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatianaesc/livroescd/blob/main/livro_ESCD_classificacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Livro Engenharia de Software para Ciência de Dados (Ed. Casa do Código)\n",
        "Marcos Kalinowski, Tatiana Escovedo, Hugo Villamizar e Hélio Lopes\n",
        "\n",
        "### Exemplo Prático de Classificação em Python"
      ],
      "metadata": {
        "id": "nwOC9PEl0SZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para ilustrar como aplicamos os algoritmos de Machine Learning na prática, vamos examinar o popular dataset Wine (disponível em https://archive.ics.uci.edu/ml/datasets/Wine), extraído a partir de uma análise química de vinhos cultivados na mesma região da Itália, mas derivados de três produtores diferentes. O objetivo deste dataset é identificar o produtor do vinho com base em 13 características químicas do vinho, ou seja, é um problema de Classificação. O dataset contém 178 instâncias (linhas), sendo 59 do produtor 1, 71 do do produtor 2 e 48 do produtor 3.\n",
        "\n",
        "Vejamos um exemplo de código em Python usando a biblioteca Scikit-learn (https://scikit-learn.org/), uma das bibliotecas Python mais utilizadas para Machine Learning. Primeiramente, vamos carregar o dataset e separar em bases de treino e teste através do método holdout. Em seguida, para a base de treino, vamos avaliar a acurácia dos modelos treinados com os algoritmos Regressão Logística, KNN, Árvore de Classificação, Naive Bayes e SVM, utilizando sua configuração padrão da biblioteca Scikit-learn, ou seja, sem variar seus hiperparâmetros (exceto na Regressão Logística, em que utilizaremos um parâmetro para limitar o número de iterações e evitar que o código demore muito tempo para ser executado). Para uma melhor avaliação, utilizaremos o método de validação cruzada 10 fold e compararemos os resultados graficamente através de boxplots.\n",
        "\n",
        "Todo o código está comentado, para facilitar o entendimento. Iniciaremos esta prática importando os pacotes necessários para o notebook:"
      ],
      "metadata": {
        "id": "oZmSvm280W0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAA_HzjG0ARI"
      },
      "outputs": [],
      "source": [
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_wine # para importar o dataset wine\n",
        "from sklearn.model_selection import train_test_split # para particionar em bases de treino e teste (holdout)\n",
        "from sklearn.model_selection import KFold # para preparar os folds da validação cruzada\n",
        "from sklearn.model_selection import cross_val_score # para executar a validação cruzada\n",
        "from sklearn.metrics import accuracy_score # para a exibição da acurácia do modelo\n",
        "from sklearn.linear_model import LogisticRegression # algoritmo Regressão Logística\n",
        "from sklearn.neighbors import KNeighborsClassifier # algoritmo KNN\n",
        "from sklearn.tree import DecisionTreeClassifier # algoritmo Árvore de Classificação\n",
        "from sklearn.naive_bayes import GaussianNB # algoritmo Naive Bayes\n",
        "from sklearn.svm import SVC # algoritmo SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seguir, iremos preparar os dados. Iremos carregar o dataset a partir da bilbioteca Scikit-learn, aplicar o holdout para efetuar a divisão em bases de treino (80%) e teste (20%) e separar em 10 folds usando a validação cruzada."
      ],
      "metadata": {
        "id": "fUj_Mq5w5-Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga do dataset\n",
        "wine = load_wine()\n",
        "dataset = pd.DataFrame(wine.data, columns=wine.feature_names) # conversão para dataframe\n",
        "dataset['target'] = wine.target # adição da coluna target\n",
        "\n",
        "# Separação em bases de treino e teste (holdout)\n",
        "array = dataset.values\n",
        "X = array[:,0:13] # atributos\n",
        "y = array[:,13] # classe (target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7) # faz a divisão\n",
        "\n",
        "# Definindo a métrica de avaliação dos algoritmos\n",
        "scoring = 'accuracy'\n",
        "\n",
        "# Criando os folds para a validação cruzada\n",
        "num_particoes = 10 # número de folds da validação cruzada\n",
        "kfold = KFold(n_splits=num_particoes, shuffle=True, random_state=7) # faz o particionamento em 10 folds"
      ],
      "metadata": {
        "id": "F2L7o57Y6AnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, passaremos para a etapa de modelagem. Definiremos uma semente global para esta célula de código (a semente é necessária para garantir a reprodutibilidade deste código, com os mesmos resultados) e iremos criar os modelos com os algoritmos KNN, Árvore de Classificação, Naive Bayes e SVM, adicionando-os numa lista. Depois, cada um destes modelos será treinado e avaliado com a base de treino, usando a validação cruzada 10-fold. O resultado médio da acurácia de cada modelo será impresso, bem como um gráfico boxplot sumarizando os resultados das 10 execuções (correspondentes aos 10 folds)."
      ],
      "metadata": {
        "id": "LA1FGEpy6CNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelagem\n",
        "\n",
        "# Definindo uma seed global para esta célula de código\n",
        "np.random.seed(7) \n",
        "\n",
        "# Listas para armazenar os modelos, os resultados e os nomes dos modelos\n",
        "models = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Preparando os modelos e adicionando-os em uma lista\n",
        "models.append(('LR', LogisticRegression(max_iter=200)))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Avaliando um modelo por vez\n",
        "for name, model in models:\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) # média e desvio padrão dos 10 resultados da validação cruzada\n",
        "  print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure() \n",
        "fig.suptitle('Comparação da Acurácia dos Modelos') \n",
        "ax = fig.add_subplot(111) \n",
        "plt.boxplot(results) \n",
        "ax.set_xticklabels(names) \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "NPgxAdOZ6CVw",
        "outputId": "4ba3be14-4830-4f51-d07b-d35b70ab0f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: 0.943810 (0.051981)\n",
            "KNN: 0.675238 (0.087929)\n",
            "CART: 0.880476 (0.055183)\n",
            "NB: 0.971429 (0.047380)\n",
            "SVM: 0.683333 (0.078282)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisando os resultados, verificamos que, considerando a acurácia média, o modelo treinado com o Naive Bayes apresentou os melhores resultados (97% de acurácia média) seguido do modelo treinado com a Regressão Logística (94% de acurácia média), ambos com desvio padrão equivalente (5%). Já analisando os bloxpots, vemos que a mediana da acurácia do modelo treinado com o Naive Bayes é superior à do modelo treinado com a Regressão Logística, indicando que possivelmente seguiríamos com o Naive Bayes como escolha de algoritmo. Neste caso, construiremos um novo modelo, treinado com toda a base de treino. Este modelo será avaliado utilizando a base de teste:"
      ],
      "metadata": {
        "id": "BLMBfpkT6Cco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um modelo com todo o conjunto de treino\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo as predições com o conjunto de teste\n",
        "predictions = model.predict(X_test) \n",
        "\n",
        "# Estimando a acurácia no conjunto de teste\n",
        "print(accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-m0E73j6CiY",
        "outputId": "2fe8c956-5539-4ad7-c759-9b3742b21135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repare que conseguimos obter uma acurácia de teste de 100%. Reforçamos que este resultado não é comum quando trabalhamos com dados de problemas reais, mas possível com datasets simplificados similares a este, trabalhados e disponibilizados apenas para fins acadêmicos.\n",
        "\n",
        "Ressaltamos que esse é um exemplo simples, apenas para ilustrar neste livro a aplicação de algoritmos de Machine Learning. Em problemas reais (com dados mais \"sujos\" e complexos), iríamos provavelmente trabalhar com algumas operações de pré-processamento de dados (tais como Normalização e Padronização, para dados quantitativos, e One-Hot-Encoding, para dados qualitativos nominais) e também experimentar variar os hiperparâmetros dos algoritmos, o que resultaria em um código mais complexo, como veremos nos capítulos a seguir."
      ],
      "metadata": {
        "id": "Ll0vZuLH6Coy"
      }
    }
  ]
}